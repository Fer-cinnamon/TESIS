{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time,random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mesindexacion</th>\n",
       "      <th>mesindexacion2</th>\n",
       "      <th>añoindexacion</th>\n",
       "      <th>licitacion</th>\n",
       "      <th>generadora</th>\n",
       "      <th>tipobloque</th>\n",
       "      <th>bloque</th>\n",
       "      <th>decpnudo</th>\n",
       "      <th>tipodecreto</th>\n",
       "      <th>mesreferencia</th>\n",
       "      <th>...</th>\n",
       "      <th>indice_CARBÓN</th>\n",
       "      <th>indice_CARBÓN_6M</th>\n",
       "      <th>indice_CPI</th>\n",
       "      <th>indice_CPI_4M</th>\n",
       "      <th>indice_CPI_6M</th>\n",
       "      <th>indice_CPI_9M</th>\n",
       "      <th>indice_GNL</th>\n",
       "      <th>indice_GNL_4M</th>\n",
       "      <th>indice_GNL_6M</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>CGED 2008/01</td>\n",
       "      <td>CAMPANARIO</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS1</td>\n",
       "      <td>130/2008</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_CGED 2008/01_CAMPANARIO_BS1_BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>CGED 2008/01</td>\n",
       "      <td>CAMPANARIO</td>\n",
       "      <td>BV</td>\n",
       "      <td>BS1</td>\n",
       "      <td>130/2008</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_CGED 2008/01_CAMPANARIO_BS1_BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>CGED 2008/01</td>\n",
       "      <td>COLBÚN</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS1</td>\n",
       "      <td>130/2008</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_CGED 2008/01_COLBÚN_BS1_BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>CGED 2008/01</td>\n",
       "      <td>COLBÚN</td>\n",
       "      <td>BV</td>\n",
       "      <td>BS1</td>\n",
       "      <td>130/2008</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_CGED 2008/01_COLBÚN_BS1_BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>CGED 2008/01</td>\n",
       "      <td>ENDESA</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS2</td>\n",
       "      <td>130/2008</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_CGED 2008/01_ENDESA_BS2_BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16090</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>SIC 2013/03_2 (ENELSA)</td>\n",
       "      <td>SAN JUAN SPA.</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS2A</td>\n",
       "      <td>4T/2013</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_SIC 2013/03_2 (ENELSA)_SAN JUAN SPA._BS2A_BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16091</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>SIC 2013/03_2 (ENELSA)</td>\n",
       "      <td>SAN JUAN SPA.</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS2C</td>\n",
       "      <td>4T/2013</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_SIC 2013/03_2 (ENELSA)_SAN JUAN SPA._BS2C_BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16092</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>SIC 2013/03_2 (ENELSA)</td>\n",
       "      <td>SAN JUAN SPA.</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS3</td>\n",
       "      <td>4T/2013</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_SIC 2013/03_2 (ENELSA)_SAN JUAN SPA._BS3_BB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16093</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>SIC 2013/03_2 (ENELSA)</td>\n",
       "      <td>SANTIAGO SOLAR S.A.</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS2B</td>\n",
       "      <td>4T/2013</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_SIC 2013/03_2 (ENELSA)_SANTIAGO SOLAR S.A._...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16094</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>SIC 2013/03_2 (ENELSA)</td>\n",
       "      <td>SPV P4 S.A.</td>\n",
       "      <td>BB</td>\n",
       "      <td>BS1B</td>\n",
       "      <td>4T/2013</td>\n",
       "      <td>Decreto PN</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_SIC 2013/03_2 (ENELSA)_SPV P4 S.A._BS1B_BB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16095 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mesindexacion  mesindexacion2  añoindexacion              licitacion  \\\n",
       "0        2010-01-01               1           2010            CGED 2008/01   \n",
       "1        2010-01-01               1           2010            CGED 2008/01   \n",
       "2        2010-01-01               1           2010            CGED 2008/01   \n",
       "3        2010-01-01               1           2010            CGED 2008/01   \n",
       "4        2010-01-01               1           2010            CGED 2008/01   \n",
       "...             ...             ...            ...                     ...   \n",
       "16090    2022-12-01              12           2022  SIC 2013/03_2 (ENELSA)   \n",
       "16091    2022-12-01              12           2022  SIC 2013/03_2 (ENELSA)   \n",
       "16092    2022-12-01              12           2022  SIC 2013/03_2 (ENELSA)   \n",
       "16093    2022-12-01              12           2022  SIC 2013/03_2 (ENELSA)   \n",
       "16094    2022-12-01              12           2022  SIC 2013/03_2 (ENELSA)   \n",
       "\n",
       "                generadora tipobloque bloque  decpnudo tipodecreto  \\\n",
       "0               CAMPANARIO         BB    BS1  130/2008  Decreto PN   \n",
       "1               CAMPANARIO         BV    BS1  130/2008  Decreto PN   \n",
       "2                   COLBÚN         BB    BS1  130/2008  Decreto PN   \n",
       "3                   COLBÚN         BV    BS1  130/2008  Decreto PN   \n",
       "4                   ENDESA         BB    BS2  130/2008  Decreto PN   \n",
       "...                    ...        ...    ...       ...         ...   \n",
       "16090        SAN JUAN SPA.         BB   BS2A   4T/2013  Decreto PN   \n",
       "16091        SAN JUAN SPA.         BB   BS2C   4T/2013  Decreto PN   \n",
       "16092        SAN JUAN SPA.         BB    BS3   4T/2013  Decreto PN   \n",
       "16093  SANTIAGO SOLAR S.A.         BB   BS2B   4T/2013  Decreto PN   \n",
       "16094          SPV P4 S.A.         BB   BS1B   4T/2013  Decreto PN   \n",
       "\n",
       "       mesreferencia  ... indice_CARBÓN  indice_CARBÓN_6M  indice_CPI  \\\n",
       "0                  1  ...             0                 0           0   \n",
       "1                  1  ...             0                 0           0   \n",
       "2                  1  ...             0                 0           0   \n",
       "3                  1  ...             0                 0           0   \n",
       "4                  1  ...             0                 0           0   \n",
       "...              ...  ...           ...               ...         ...   \n",
       "16090             12  ...             0                 0           0   \n",
       "16091             12  ...             0                 0           0   \n",
       "16092             12  ...             0                 0           0   \n",
       "16093             12  ...             0                 0           0   \n",
       "16094             12  ...             0                 0           0   \n",
       "\n",
       "       indice_CPI_4M  indice_CPI_6M  indice_CPI_9M  indice_GNL  indice_GNL_4M  \\\n",
       "0                  0              0              1           0              0   \n",
       "1                  0              0              1           0              0   \n",
       "2                  0              0              1           0              0   \n",
       "3                  0              0              1           0              0   \n",
       "4                  0              0              1           0              0   \n",
       "...              ...            ...            ...         ...            ...   \n",
       "16090              0              1              0           0              0   \n",
       "16091              0              1              0           0              0   \n",
       "16092              0              1              0           0              0   \n",
       "16093              0              1              0           0              0   \n",
       "16094              0              1              0           0              0   \n",
       "\n",
       "       indice_GNL_6M                                          unique_id  \n",
       "0                  0                  ID_CGED 2008/01_CAMPANARIO_BS1_BB  \n",
       "1                  0                  ID_CGED 2008/01_CAMPANARIO_BS1_BV  \n",
       "2                  0                      ID_CGED 2008/01_COLBÚN_BS1_BB  \n",
       "3                  0                      ID_CGED 2008/01_COLBÚN_BS1_BV  \n",
       "4                  0                      ID_CGED 2008/01_ENDESA_BS2_BB  \n",
       "...              ...                                                ...  \n",
       "16090              0    ID_SIC 2013/03_2 (ENELSA)_SAN JUAN SPA._BS2A_BB  \n",
       "16091              0    ID_SIC 2013/03_2 (ENELSA)_SAN JUAN SPA._BS2C_BB  \n",
       "16092              0     ID_SIC 2013/03_2 (ENELSA)_SAN JUAN SPA._BS3_BB  \n",
       "16093              0  ID_SIC 2013/03_2 (ENELSA)_SANTIAGO SOLAR S.A._...  \n",
       "16094              0      ID_SIC 2013/03_2 (ENELSA)_SPV P4 S.A._BS1B_BB  \n",
       "\n",
       "[16095 rows x 34 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_excel('C:/Users/Asus/Escritorio/Universidad/Nivel 12/TESIS/series_tiempo.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['unique_id'] == 'ID_EMEL-SIC 2006/01-2 (EMETAL)_AES GENER_BB_Sur_BB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de nombres de las variables que quieres eliminar\n",
    "variables_a_eliminar = ['licitacion',\n",
    "       'generadora', 'tipobloque', 'bloque', 'decpnudo', 'tipodecreto',\n",
    "       'mesreferencia', 'ptooferta', 'valorbase',\n",
    "       'precioenergiabase',\n",
    "       'añoreferencia', 'añobase', 'mesbase', 'rezago_2.0',\n",
    "       'rezago_3.0', 'indice_BRENT_6M', 'indice_CARBÓN', 'indice_CARBÓN_6M',\n",
    "       'indice_CPI', 'indice_CPI_4M', 'indice_CPI_6M', 'indice_CPI_9M',\n",
    "       'indice_GNL', 'indice_GNL_4M', 'indice_GNL_6M','unique_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12336\\829567979.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(variables_a_eliminar, axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mesindexacion</th>\n",
       "      <th>mesindexacion2</th>\n",
       "      <th>añoindexacion</th>\n",
       "      <th>precioindexadoponderado</th>\n",
       "      <th>valoractual</th>\n",
       "      <th>factorindexacion</th>\n",
       "      <th>añoactual</th>\n",
       "      <th>mesactual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>70.433561</td>\n",
       "      <td>91.14</td>\n",
       "      <td>1.341873</td>\n",
       "      <td>2009</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>73.424321</td>\n",
       "      <td>95.01</td>\n",
       "      <td>1.398852</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>77.296080</td>\n",
       "      <td>100.02</td>\n",
       "      <td>1.472615</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>79.467666</td>\n",
       "      <td>102.83</td>\n",
       "      <td>1.513987</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>81.299217</td>\n",
       "      <td>105.20</td>\n",
       "      <td>1.548881</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15196</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>269.887124</td>\n",
       "      <td>349.23</td>\n",
       "      <td>5.141784</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15393</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>266.973645</td>\n",
       "      <td>345.46</td>\n",
       "      <td>5.086278</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>10</td>\n",
       "      <td>2022</td>\n",
       "      <td>247.182077</td>\n",
       "      <td>319.85</td>\n",
       "      <td>4.709217</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>11</td>\n",
       "      <td>2022</td>\n",
       "      <td>272.035525</td>\n",
       "      <td>352.01</td>\n",
       "      <td>5.182715</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15984</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>291.602980</td>\n",
       "      <td>377.33</td>\n",
       "      <td>5.555506</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mesindexacion  mesindexacion2  añoindexacion  precioindexadoponderado  \\\n",
       "17       2010-01-01               1           2010                70.433561   \n",
       "35       2010-02-01               2           2010                73.424321   \n",
       "53       2010-03-01               3           2010                77.296080   \n",
       "71       2010-04-01               4           2010                79.467666   \n",
       "89       2010-05-01               5           2010                81.299217   \n",
       "...             ...             ...            ...                      ...   \n",
       "15196    2022-08-01               8           2022               269.887124   \n",
       "15393    2022-09-01               9           2022               266.973645   \n",
       "15590    2022-10-01              10           2022               247.182077   \n",
       "15787    2022-11-01              11           2022               272.035525   \n",
       "15984    2022-12-01              12           2022               291.602980   \n",
       "\n",
       "       valoractual  factorindexacion  añoactual  mesactual  \n",
       "17           91.14          1.341873       2009         11  \n",
       "35           95.01          1.398852       2009         12  \n",
       "53          100.02          1.472615       2010          1  \n",
       "71          102.83          1.513987       2010          2  \n",
       "89          105.20          1.548881       2010          3  \n",
       "...            ...               ...        ...        ...  \n",
       "15196       349.23          5.141784       2022          6  \n",
       "15393       345.46          5.086278       2022          7  \n",
       "15590       319.85          4.709217       2022          8  \n",
       "15787       352.01          5.182715       2022          9  \n",
       "15984       377.33          5.555506       2022         10  \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(variables_a_eliminar, axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mesindexacion</th>\n",
       "      <th>precioindexadoponderado</th>\n",
       "      <th>valoractual</th>\n",
       "      <th>factorindexacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>70.433561</td>\n",
       "      <td>91.14</td>\n",
       "      <td>1.341873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>73.424321</td>\n",
       "      <td>95.01</td>\n",
       "      <td>1.398852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>77.296080</td>\n",
       "      <td>100.02</td>\n",
       "      <td>1.472615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>79.467666</td>\n",
       "      <td>102.83</td>\n",
       "      <td>1.513987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2010-05-01</td>\n",
       "      <td>81.299217</td>\n",
       "      <td>105.20</td>\n",
       "      <td>1.548881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15196</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>269.887124</td>\n",
       "      <td>349.23</td>\n",
       "      <td>5.141784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15393</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>266.973645</td>\n",
       "      <td>345.46</td>\n",
       "      <td>5.086278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>247.182077</td>\n",
       "      <td>319.85</td>\n",
       "      <td>4.709217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>272.035525</td>\n",
       "      <td>352.01</td>\n",
       "      <td>5.182715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15984</th>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>291.602980</td>\n",
       "      <td>377.33</td>\n",
       "      <td>5.555506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mesindexacion  precioindexadoponderado  valoractual  factorindexacion\n",
       "17       2010-01-01                70.433561        91.14          1.341873\n",
       "35       2010-02-01                73.424321        95.01          1.398852\n",
       "53       2010-03-01                77.296080       100.02          1.472615\n",
       "71       2010-04-01                79.467666       102.83          1.513987\n",
       "89       2010-05-01                81.299217       105.20          1.548881\n",
       "...             ...                      ...          ...               ...\n",
       "15196    2022-08-01               269.887124       349.23          5.141784\n",
       "15393    2022-09-01               266.973645       345.46          5.086278\n",
       "15590    2022-10-01               247.182077       319.85          4.709217\n",
       "15787    2022-11-01               272.035525       352.01          5.182715\n",
       "15984    2022-12-01               291.602980       377.33          5.555506\n",
       "\n",
       "[156 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop(['mesindexacion2', 'añoindexacion', 'añoactual','mesactual'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precioindexadoponderado</th>\n",
       "      <th>valoractual</th>\n",
       "      <th>factorindexacion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesindexacion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>70.433561</td>\n",
       "      <td>91.14</td>\n",
       "      <td>1.341873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>73.424321</td>\n",
       "      <td>95.01</td>\n",
       "      <td>1.398852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>77.296080</td>\n",
       "      <td>100.02</td>\n",
       "      <td>1.472615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>79.467666</td>\n",
       "      <td>102.83</td>\n",
       "      <td>1.513987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>81.299217</td>\n",
       "      <td>105.20</td>\n",
       "      <td>1.548881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "      <td>269.887124</td>\n",
       "      <td>349.23</td>\n",
       "      <td>5.141784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>266.973645</td>\n",
       "      <td>345.46</td>\n",
       "      <td>5.086278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-01</th>\n",
       "      <td>247.182077</td>\n",
       "      <td>319.85</td>\n",
       "      <td>4.709217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>272.035525</td>\n",
       "      <td>352.01</td>\n",
       "      <td>5.182715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-01</th>\n",
       "      <td>291.602980</td>\n",
       "      <td>377.33</td>\n",
       "      <td>5.555506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               precioindexadoponderado  valoractual  factorindexacion\n",
       "mesindexacion                                                        \n",
       "2010-01-01                   70.433561        91.14          1.341873\n",
       "2010-02-01                   73.424321        95.01          1.398852\n",
       "2010-03-01                   77.296080       100.02          1.472615\n",
       "2010-04-01                   79.467666       102.83          1.513987\n",
       "2010-05-01                   81.299217       105.20          1.548881\n",
       "...                                ...          ...               ...\n",
       "2022-08-01                  269.887124       349.23          5.141784\n",
       "2022-09-01                  266.973645       345.46          5.086278\n",
       "2022-10-01                  247.182077       319.85          4.709217\n",
       "2022-11-01                  272.035525       352.01          5.182715\n",
       "2022-12-01                  291.602980       377.33          5.555506\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('mesindexacion', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características (X) y la variable objetivo (y)\n",
    "\n",
    "X = df[['valoractual', 'factorindexacion']]\n",
    "y = df['precioindexadoponderado']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlación de Pearson:\n",
      "Las siguientes características están altamente correlacionadas (>0.75): ['factorindexacion'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcular la matriz de correlación de Pearson\n",
    "\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# Filtrar las correlaciones mayores a 0.75\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
    "\n",
    "print(\"Correlación de Pearson:\\nLas siguientes características están altamente correlacionadas (>0.75):\", to_drop, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancia de la Característica del Árbol de Decisión:\n",
      "             Feature  Importance\n",
      "1  factorindexacion     0.60334\n",
      "0       valoractual     0.39666 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 4. Importancia de la Característica del Árbol de Decisión\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, y)\n",
    "importance = model.feature_importances_\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importance})\n",
    "print(\"Importancia de la Característica del Árbol de Decisión:\\n\", feature_importance.nlargest(4, 'Importance'), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precioindexadoponderado</th>\n",
       "      <th>valoractual</th>\n",
       "      <th>factorindexacion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesindexacion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>0.074238</td>\n",
       "      <td>0.074238</td>\n",
       "      <td>0.074238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>0.086757</td>\n",
       "      <td>0.086757</td>\n",
       "      <td>0.086757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>0.102963</td>\n",
       "      <td>0.102963</td>\n",
       "      <td>0.102963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>0.112053</td>\n",
       "      <td>0.112053</td>\n",
       "      <td>0.112053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.119719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precioindexadoponderado  valoractual  factorindexacion\n",
       "mesindexacion                                                        \n",
       "2010-01-01                    0.074238     0.074238          0.074238\n",
       "2010-02-01                    0.086757     0.086757          0.086757\n",
       "2010-03-01                    0.102963     0.102963          0.102963\n",
       "2010-04-01                    0.112053     0.112053          0.112053\n",
       "2010-05-01                    0.119719     0.119719          0.119719"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "#Seleccion de caracteristicas\n",
    "features =df.columns\n",
    "\n",
    "#Se define escalado\n",
    "std_scaler = StandardScaler()\n",
    "min_scaler=MinMaxScaler()\n",
    "\n",
    "#Transformacion\n",
    "\n",
    "for i in features:\n",
    "  df[i] = min_scaler.fit_transform(df[i].values.reshape(-1,1))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['valoractual', 'factorindexacion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define escalado\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "series_time_scaled=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Después de la estandarización:\n",
      "               valoractual  factorindexacion\n",
      "mesindexacion                               \n",
      "2010-01-01       -0.602608          0.074238\n",
      "2010-02-01       -0.531163          0.086757\n",
      "2010-03-01       -0.438671          0.102963\n",
      "2010-04-01       -0.386794          0.112053\n",
      "2010-05-01       -0.343041          0.119719\n",
      "...                    ...               ...\n",
      "2022-08-01        4.162104          0.909103\n",
      "2022-09-01        4.092504          0.896908\n",
      "2022-10-01        3.619707          0.814065\n",
      "2022-11-01        4.213426          0.918095\n",
      "2022-12-01        4.680870          1.000000\n",
      "\n",
      "[156 rows x 2 columns]\n",
      "\n",
      "Después de la estandarización:\n",
      "               valoractual  factorindexacion\n",
      "mesindexacion                               \n",
      "2010-01-01       -0.602608         -0.602608\n",
      "2010-02-01       -0.531163         -0.531163\n",
      "2010-03-01       -0.438671         -0.438671\n",
      "2010-04-01       -0.386794         -0.386794\n",
      "2010-05-01       -0.343041         -0.343041\n",
      "...                    ...               ...\n",
      "2022-08-01        4.162104          4.162104\n",
      "2022-09-01        4.092504          4.092504\n",
      "2022-10-01        3.619707          3.619707\n",
      "2022-11-01        4.213426          4.213426\n",
      "2022-12-01        4.680870          4.680870\n",
      "\n",
      "[156 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[               precioindexadoponderado  valoractual  factorindexacion\n",
       " mesindexacion                                                        \n",
       " 2010-01-01                    0.074238    -0.602608         -0.602608\n",
       " 2010-02-01                    0.086757    -0.531163         -0.531163\n",
       " 2010-03-01                    0.102963    -0.438671         -0.438671\n",
       " 2010-04-01                    0.112053    -0.386794         -0.386794\n",
       " 2010-05-01                    0.119719    -0.343041         -0.343041\n",
       " ...                                ...          ...               ...\n",
       " 2022-08-01                    0.909103     4.162104          4.162104\n",
       " 2022-09-01                    0.896908     4.092504          4.092504\n",
       " 2022-10-01                    0.814065     3.619707          3.619707\n",
       " 2022-11-01                    0.918095     4.213426          4.213426\n",
       " 2022-12-01                    1.000000     4.680870          4.680870\n",
       " \n",
       " [156 rows x 3 columns]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suponiendo que 'features' es una lista de características que se deben estandarizar\n",
    "\n",
    "# Crear una instancia de StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "    \n",
    "    # Iterar a través de cada característica en la lista 'features'\n",
    "for nombre_caracteristica in features:\n",
    "        # Extraer los valores de la característica actual y darle forma a (-1, 1)\n",
    "    valores_caracteristica = df[nombre_caracteristica].values.reshape(-1, 1)\n",
    "        \n",
    "        # Aplicar la estandarización a los valores de la característica\n",
    "    valores_estandarizados = std_scaler.fit_transform(valores_caracteristica)\n",
    "        \n",
    "        # Reemplazar los valores originales de la característica con los valores estandarizados en la serie\n",
    "    df[nombre_caracteristica] = valores_estandarizados\n",
    "    \n",
    "    print(f\"\\nDespués de la estandarización:\\n{df[features]}\")\n",
    "\n",
    "# Crear una nueva lista para almacenar las series estandarizadas\n",
    "series_time_scaled.append(df)\n",
    "series_time_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precioindexadoponderado  valoractual  factorindexacion\n",
      "mesindexacion                                                        \n",
      "2010-01-01                    0.074238    -0.602608         -0.602608\n",
      "2010-02-01                    0.086757    -0.531163         -0.531163\n",
      "2010-03-01                    0.102963    -0.438671         -0.438671\n",
      "2010-04-01                    0.112053    -0.386794         -0.386794\n",
      "2010-05-01                    0.119719    -0.343041         -0.343041\n",
      "...                                ...          ...               ...\n",
      "2022-08-01                    0.909103     4.162104          4.162104\n",
      "2022-09-01                    0.896908     4.092504          4.092504\n",
      "2022-10-01                    0.814065     3.619707          3.619707\n",
      "2022-11-01                    0.918095     4.213426          4.213426\n",
      "2022-12-01                    1.000000     4.680870          4.680870\n",
      "\n",
      "[156 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que 'series_time_scaled' es tu lista que contiene un solo DataFrame\n",
    "data_frame_individual = series_time_scaled[0]\n",
    "\n",
    "# Convertir el DataFrame a un nuevo DataFrame\n",
    "df2 = pd.DataFrame(data_frame_individual)\n",
    "\n",
    "\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_delay_embedding(series: pd.Series, n_lags: int, horizon: int):\n",
    "    \"\"\"\n",
    "    Incrustación de retardo de tiempo\n",
    "    :param series: serie de tiempo como objeto de pandas\n",
    "    :param n_lags: número de valores pasados para usar como variables explicativas\n",
    "    :param horizon: horizonte de pronostico\n",
    "    :return:pd.DataFrame con series temporales reconstruidas\n",
    "    \"\"\"\n",
    "    assert isinstance(series, pd.Series)\n",
    "\n",
    "    if series.name is None:\n",
    "        name = 'Series'\n",
    "    else:\n",
    "        name = series.name\n",
    "\n",
    "    n_lags_iter = list(range(n_lags, -horizon, -1))\n",
    "\n",
    "    serie_time_delay = [series.shift(i) for i in n_lags_iter]\n",
    "    serie_time_delay = pd.concat(serie_time_delay, axis=1).dropna()\n",
    "    serie_time_delay.columns = [f'{name}(t-{j - 1})'\n",
    "                 if j > 0 else f'{name}(t+{np.abs(j) + 1})'\n",
    "                 for j in n_lags_iter]\n",
    "\n",
    "    return serie_time_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[               precioindexadoponderado  valoractual  factorindexacion\n",
       " mesindexacion                                                        \n",
       " 2010-01-01                    0.074238    -0.602608         -0.602608\n",
       " 2010-02-01                    0.086757    -0.531163         -0.531163\n",
       " 2010-03-01                    0.102963    -0.438671         -0.438671\n",
       " 2010-04-01                    0.112053    -0.386794         -0.386794\n",
       " 2010-05-01                    0.119719    -0.343041         -0.343041\n",
       " ...                                ...          ...               ...\n",
       " 2022-08-01                    0.909103     4.162104          4.162104\n",
       " 2022-09-01                    0.896908     4.092504          4.092504\n",
       " 2022-10-01                    0.814065     3.619707          3.619707\n",
       " 2022-11-01                    0.918095     4.213426          4.213426\n",
       " 2022-12-01                    1.000000     4.680870          4.680870\n",
       " \n",
       " [156 rows x 3 columns]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_time_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_predic=[]\n",
    "series_target=[]\n",
    "serie_split = []\n",
    "for columna in df2:\n",
    "  col_df = time_delay_embedding(\n",
    "      df2[columna], #Serie de tiempo\n",
    "      n_lags=1, #Numero de retrasos\n",
    "      horizon=1 # Horizonte de prediccion\n",
    "      )\n",
    "  serie_split.append(col_df)\n",
    "\n",
    "serie_df = pd.concat(serie_split, axis=1).dropna()\n",
    "serie_df.head()\n",
    "\n",
    "predictor_variables = serie_df.columns.str.contains('valoractual','factorindexacion')\n",
    "target_variables = serie_df.columns.str.contains('precioindexadoponderado\\(t\\+')\n",
    "series_predic.append(predictor_variables)\n",
    "series_target.append(target_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precioindexadoponderado(t-0)</th>\n",
       "      <th>precioindexadoponderado(t+1)</th>\n",
       "      <th>valoractual(t-0)</th>\n",
       "      <th>valoractual(t+1)</th>\n",
       "      <th>factorindexacion(t-0)</th>\n",
       "      <th>factorindexacion(t+1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mesindexacion</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-02-01</th>\n",
       "      <td>0.074238</td>\n",
       "      <td>0.086757</td>\n",
       "      <td>-0.602608</td>\n",
       "      <td>-0.531163</td>\n",
       "      <td>-0.602608</td>\n",
       "      <td>-0.531163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-01</th>\n",
       "      <td>0.086757</td>\n",
       "      <td>0.102963</td>\n",
       "      <td>-0.531163</td>\n",
       "      <td>-0.438671</td>\n",
       "      <td>-0.531163</td>\n",
       "      <td>-0.438671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>0.102963</td>\n",
       "      <td>0.112053</td>\n",
       "      <td>-0.438671</td>\n",
       "      <td>-0.386794</td>\n",
       "      <td>-0.438671</td>\n",
       "      <td>-0.386794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>0.112053</td>\n",
       "      <td>0.119719</td>\n",
       "      <td>-0.386794</td>\n",
       "      <td>-0.343041</td>\n",
       "      <td>-0.386794</td>\n",
       "      <td>-0.343041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-01</th>\n",
       "      <td>0.119719</td>\n",
       "      <td>0.113638</td>\n",
       "      <td>-0.343041</td>\n",
       "      <td>-0.377748</td>\n",
       "      <td>-0.343041</td>\n",
       "      <td>-0.377748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precioindexadoponderado(t-0)  precioindexadoponderado(t+1)  \\\n",
       "mesindexacion                                                               \n",
       "2010-02-01                         0.074238                      0.086757   \n",
       "2010-03-01                         0.086757                      0.102963   \n",
       "2010-04-01                         0.102963                      0.112053   \n",
       "2010-05-01                         0.112053                      0.119719   \n",
       "2010-06-01                         0.119719                      0.113638   \n",
       "\n",
       "               valoractual(t-0)  valoractual(t+1)  factorindexacion(t-0)  \\\n",
       "mesindexacion                                                              \n",
       "2010-02-01            -0.602608         -0.531163              -0.602608   \n",
       "2010-03-01            -0.531163         -0.438671              -0.531163   \n",
       "2010-04-01            -0.438671         -0.386794              -0.438671   \n",
       "2010-05-01            -0.386794         -0.343041              -0.386794   \n",
       "2010-06-01            -0.343041         -0.377748              -0.343041   \n",
       "\n",
       "               factorindexacion(t+1)  \n",
       "mesindexacion                         \n",
       "2010-02-01                 -0.531163  \n",
       "2010-03-01                 -0.438671  \n",
       "2010-04-01                 -0.386794  \n",
       "2010-05-01                 -0.343041  \n",
       "2010-06-01                 -0.377748  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_df = pd.concat(serie_split, axis=1).dropna()\n",
    "serie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_variables = serie_df.columns.str.contains('\\(t\\-')\n",
    "target_variables = serie_df.columns.str.contains('precioindexadoponderado\\(t\\+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_supervised = serie_df.iloc[:, predictor_variables]\n",
    "test_supervised = serie_df.iloc[:, target_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separacion de datos terminada!\n"
     ]
    }
   ],
   "source": [
    "#Se separa conjunto en entrenamiento y prueba; sin aleatoriedad\n",
    "#Dejando un %20 de la data para test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_supervised, test_supervised, test_size=0.2, shuffle=False)\n",
    "\n",
    "shape=len(X_train.columns)\n",
    "\n",
    "print(\"Separacion de datos terminada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_aux=Y_train\n",
    "Y_test_aux = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precioindexadoponderado(t+1)\n",
      "mesindexacion                              \n",
      "2020-06-01                         0.062690\n",
      "2020-07-01                         0.051465\n",
      "2020-08-01                         0.034612\n",
      "2020-09-01                         0.023032\n",
      "2020-10-01                         0.034677\n",
      "2020-11-01                         0.043928\n",
      "2020-12-01                         0.045028\n",
      "2021-01-01                         0.051951\n",
      "2021-02-01                         0.055865\n",
      "2021-03-01                         0.058808\n",
      "2021-04-01                         0.090639\n",
      "2021-05-01                         0.093970\n",
      "2021-06-01                         0.108397\n",
      "2021-07-01                         0.117972\n",
      "2021-08-01                         0.111891\n",
      "2021-09-01                         0.138513\n",
      "2021-10-01                         0.224364\n",
      "2021-11-01                         0.307142\n",
      "2021-12-01                         0.360678\n",
      "2022-01-01                         0.442744\n",
      "2022-02-01                         0.638319\n",
      "2022-03-01                         0.457851\n",
      "2022-04-01                         0.374264\n",
      "2022-05-01                         0.431681\n",
      "2022-06-01                         0.564404\n",
      "2022-07-01                         0.915281\n",
      "2022-08-01                         0.909103\n",
      "2022-09-01                         0.896908\n",
      "2022-10-01                         0.814065\n",
      "2022-11-01                         0.918095\n",
      "2022-12-01                         1.000000\n"
     ]
    }
   ],
   "source": [
    "print (Y_test_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x_test=X_test.shape\n",
    "shape_y_test=Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pandas es utilizado para leer los set de datos\n",
    "import pandas as pd\n",
    "#Numpy es utilizado para generar las series de datos a graficar\n",
    "import numpy as np\n",
    "#Seaborn es utilizado para generar los gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "#Se importan modulos estadisticos para generar test de hipotesis, entre otros\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "#Ignorar warnings\n",
    "\n",
    "#Dividir arreglos o matrices en subconjuntos aleatorios de tren y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Biblioteca de Redes Neuronales\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dropout, GRU, Dense, Activation,Input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin, space_eval\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict, TimeSeriesSplit\n",
    "import time,os\n",
    "# Transformer with Bayesian optimization and Cross-validation\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, TimeDistributed\n",
    "from keras.layers import LayerNormalization, MultiHeadAttention, Add\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se establece porcentaje de usado para test\n",
    "PORCENTAJE_TEST=0.2\n",
    "\n",
    "#Se define la cantidad de intentos de la optimizacion bayesiana\n",
    "INTENTOS=100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mesindexacion\n",
       "2018-01-01     96.376667\n",
       "2015-10-01     69.513922\n",
       "2016-11-01     63.694691\n",
       "2016-05-01     58.941932\n",
       "2019-07-01     83.517171\n",
       "2012-06-01    100.279338\n",
       "2017-11-01     90.843374\n",
       "2021-01-01     65.108926\n",
       "2017-10-01     85.387362\n",
       "2021-08-01     79.429026\n",
       "2011-08-01    121.477413\n",
       "2017-07-01     84.568187\n",
       "2011-04-01    112.451036\n",
       "2020-06-01     67.674643\n",
       "2012-01-01    115.596358\n",
       "2012-07-01     97.937735\n",
       "2019-12-01     66.353144\n",
       "2018-06-01    101.137153\n",
       "2022-09-01    266.973645\n",
       "2016-07-01     59.421072\n",
       "2018-03-01     95.843430\n",
       "2011-07-01    119.939529\n",
       "2011-01-01     92.064408\n",
       "2010-10-01     93.996423\n",
       "2012-08-01     97.574516\n",
       "2018-09-01    100.758478\n",
       "2015-09-01     70.309912\n",
       "2014-08-01     87.489395\n",
       "2014-04-01     87.597588\n",
       "2018-02-01     97.304034\n",
       "2013-10-01     79.939078\n",
       "2022-04-01    142.111340\n",
       "Name: precioindexadoponderado, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se da formato de entradas como: Un tensor 3D con la forma [batch, timesteps, feature]\n",
    "X_train=np.array(X_train)\n",
    "X_train = X_train.reshape((X_train.shape[0],1, X_train.shape[1]))\n",
    "\n",
    "Y_train_s=np.array(Y_train)\n",
    "Y_train_s = Y_train_s.reshape((Y_train_s.shape[0],1,Y_train_s.shape[1]))\n",
    "\n",
    "X_test=np.array(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0],1, X_test.shape[1]))\n",
    "\n",
    "Y_test=np.array(Y_test)\n",
    "Y_test = Y_test.reshape((Y_test.shape[0],1, Y_test.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [01:08<26:40, 16.67s/trial, best loss: 258505.04454012573]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: Graph execution error:\n",
      "\n",
      "Detected at node 'model_521/multi_head_attention_1043/einsum/Einsum' defined at (most recent call last):\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n",
      "      app.start()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "      self.io_loop.start()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "      self._run_once()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "      handle._run()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "      await result\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12336\\13403891.py\", line 135, in <module>\n",
      "      best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=INTENTOS, trials=trials)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 540, in fmin\n",
      "      return trials.fmin(\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py\", line 671, in fmin\n",
      "      return fmin(\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 586, in fmin\n",
      "      rval.exhaust()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 364, in exhaust\n",
      "      self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 300, in run\n",
      "      self.serial_evaluate()\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 178, in serial_evaluate\n",
      "      result = self.domain.evaluate(spec, ctrl)\n",
      "    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py\", line 892, in evaluate\n",
      "      rval = self.fn(pyll_rval)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12336\\13403891.py\", line 63, in objective\n",
      "      hist=model.fit(X_train_, y_train_, batch_size=int(batch_size), epochs=int(epochs), verbose=0, validation_data=(X_test_, y_test_),callbacks=[early_stop],use_multiprocessing=True)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 598, in call\n",
      "      attention_output, attention_scores = self._compute_attention(\n",
      "    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 527, in _compute_attention\n",
      "      attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
      "Node: 'model_521/multi_head_attention_1043/einsum/Einsum'\n",
      "OOM when allocating tensor with shape[44,8,1,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[{{node model_521/multi_head_attention_1043/einsum/Einsum}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [Op:__inference_train_function_2635534]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [01:17<30:54, 19.32s/trial, best loss: 258505.04454012573]\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_521/multi_head_attention_1043/einsum/Einsum' defined at (most recent call last):\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12336\\13403891.py\", line 135, in <module>\n      best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=INTENTOS, trials=trials)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 540, in fmin\n      return trials.fmin(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py\", line 671, in fmin\n      return fmin(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 586, in fmin\n      rval.exhaust()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 364, in exhaust\n      self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 300, in run\n      self.serial_evaluate()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 178, in serial_evaluate\n      result = self.domain.evaluate(spec, ctrl)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py\", line 892, in evaluate\n      rval = self.fn(pyll_rval)\n    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12336\\13403891.py\", line 63, in objective\n      hist=model.fit(X_train_, y_train_, batch_size=int(batch_size), epochs=int(epochs), verbose=0, validation_data=(X_test_, y_test_),callbacks=[early_stop],use_multiprocessing=True)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 598, in call\n      attention_output, attention_scores = self._compute_attention(\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 527, in _compute_attention\n      attention_scores = tf.einsum(self._dot_product_equation, key, query)\nNode: 'model_521/multi_head_attention_1043/einsum/Einsum'\nOOM when allocating tensor with shape[44,8,1,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node model_521/multi_head_attention_1043/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2635534]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 135\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# Bayesian optimization\u001b[39;00m\n\u001b[0;32m    134\u001b[0m trials \u001b[38;5;241m=\u001b[39m Trials()\n\u001b[1;32m--> 135\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINTENTOS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m#Obtener el valor de la función objetivo del mejor ensayo\u001b[39;00m\n\u001b[0;32m    138\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m trials\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[1;32mc:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[38;5;241m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_trials_fmin \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(trials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;66;03m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfmin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_trials_fmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_expr_memo_ctrl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch_eval_exceptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_argmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_argmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progressbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stop_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrials_save_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrials_save_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[62], line 63\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#Entrenamiento\u001b[39;00m\n\u001b[0;32m     62\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 63\u001b[0m hist\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#Evaluacion del modelo\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_521/multi_head_attention_1043/einsum/Einsum' defined at (most recent call last):\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12336\\13403891.py\", line 135, in <module>\n      best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=INTENTOS, trials=trials)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 540, in fmin\n      return trials.fmin(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py\", line 671, in fmin\n      return fmin(\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 586, in fmin\n      rval.exhaust()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 364, in exhaust\n      self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 300, in run\n      self.serial_evaluate()\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\fmin.py\", line 178, in serial_evaluate\n      result = self.domain.evaluate(spec, ctrl)\n    File \"c:\\Users\\Asus\\.conda\\envs\\tesis\\lib\\site-packages\\hyperopt\\base.py\", line 892, in evaluate\n      rval = self.fn(pyll_rval)\n    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_12336\\13403891.py\", line 63, in objective\n      hist=model.fit(X_train_, y_train_, batch_size=int(batch_size), epochs=int(epochs), verbose=0, validation_data=(X_test_, y_test_),callbacks=[early_stop],use_multiprocessing=True)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 598, in call\n      attention_output, attention_scores = self._compute_attention(\n    File \"C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\layers\\attention\\multi_head_attention.py\", line 527, in _compute_attention\n      attention_scores = tf.einsum(self._dot_product_equation, key, query)\nNode: 'model_521/multi_head_attention_1043/einsum/Einsum'\nOOM when allocating tensor with shape[44,8,1,256] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node model_521/multi_head_attention_1043/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2635534]"
     ]
    }
   ],
   "source": [
    "# Marca el tiempo de inicio\n",
    "inicio = time.time()\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout):\n",
    "    x = LayerNormalization()(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = Add()([x, inputs])\n",
    "\n",
    "    x = LayerNormalization()(res)\n",
    "    x = Dense(ff_dim, activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return Add()([x, res])\n",
    "\n",
    "def create_model(head_size, dropout,num_heads,learning_rate,ff_dim):\n",
    "    inputs = Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "    x = inputs\n",
    "    for _ in range(2):  # two transformer blocks\n",
    "        x = transformer_encoder(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout)\n",
    "    outputs = TimeDistributed(Dense(1))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=Adam(learning_rate=learning_rate),\n",
    "                  metrics = [tf.keras.metrics.MeanSquaredError(),\n",
    "                            tf.keras.metrics.RootMeanSquaredError(),\n",
    "                            tf.keras.metrics.MeanAbsoluteError(),\n",
    "                            tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "    return model\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "    # Definir los hiperparámetros a optimizar\n",
    "    head_size = params['head_size']\n",
    "    num_heads = params['num_heads']\n",
    "    ff_dim  = params['ff_dim']\n",
    "    dropout  = params['dropout']\n",
    "    epochs = params['epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    #kf = KFold(n_splits=5)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    scores = []\n",
    "    scores_test=[]\n",
    "    times=[]\n",
    "    models=[]\n",
    "    aux=1000\n",
    "\n",
    "    #Se detiene el entrenamiento en el momento que se observe un incremento en el valor del error de validación.\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=30, mode='min',restore_best_weights=True)\n",
    "\n",
    "    #Validacion cruzada\n",
    "    for train_index, test_index in tscv.split(X_train):\n",
    "      X_train_, X_test_ = X_train[train_index], X_train[test_index]\n",
    "      y_train_, y_test_ = Y_train_s[train_index], Y_train_s[test_index]\n",
    "\n",
    "      # Crear el modelo de Transformer\n",
    "      model = create_model(int(head_size), float(dropout),int(num_heads),float(learning_rate),int(ff_dim))\n",
    "\n",
    "      #Entrenamiento\n",
    "      start = time.time()\n",
    "      hist=model.fit(X_train_, y_train_, batch_size=int(batch_size), epochs=int(epochs), verbose=0, validation_data=(X_test_, y_test_),callbacks=[early_stop],use_multiprocessing=True)\n",
    "      end = time.time()\n",
    "\n",
    "      #Evaluacion del modelo\n",
    "      score = model.evaluate(X_test_, y_test_, verbose = 0)\n",
    "      scores.append(score)\n",
    "      #Error en conjunto de test\n",
    "      score_test = model.evaluate(X_test, Y_test, verbose = 0)\n",
    "      scores_test.append(score_test)\n",
    "\n",
    "      if(score_test[0]<aux):\n",
    "        aux=score_test[0]\n",
    "        best_model=model\n",
    "        hist_=hist\n",
    "\n",
    "      #guardar modelo keras\n",
    "      models.append(model)\n",
    "\n",
    "      #Tiempo de la validadion cruzada\n",
    "      time_val= end- start\n",
    "      times.append(time_val)\n",
    "\n",
    "    return{'loss': np.mean(scores),\n",
    "            'status': STATUS_OK,\n",
    "            'model': best_model,\n",
    "            'params': params,\n",
    "            'hist':hist_,\n",
    "            'time':times,\n",
    "            'scores_test': scores_test,\n",
    "            'scores': scores,\n",
    "            'models':models}\n",
    "\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'head_size': hp.choice('head_size', [64, 128, 256]),  # Reducido a 3 opciones\n",
    "    'num_heads': hp.choice('num_heads', [4, 6, 8]),      # Reducido a 3 opciones\n",
    "    'ff_dim': hp.choice('ff_dim', [64, 128, 256]),       # Reducido a 3 opciones\n",
    "    'dropout': hp.uniform('dropout', 0.4, 0.6),          # Rango más estrecho\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.00001, 0.0001),  # Rango más amplio\n",
    "    'epochs': 5,                                       # Menos épocas\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128]) # Reducido a 3 opciones\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'head_size': hp.quniform('head_size', 64, 256, 32),\n",
    "    'num_heads':hp.quniform('num_heads', 4, 8, 1),\n",
    "    'ff_dim': hp.quniform('ff_dim', 64, 256, 32),\n",
    "    'dropout':hp.uniform('dropout', 0.4, 0.7),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.00001, 0.00005),\n",
    "    'epochs': 800,\n",
    "    'batch_size':  hp.quniform('batch_size', 10, 100, 10),\n",
    "}\n",
    "\n",
    "'''\n",
    "'''\n",
    "space = {\n",
    "    'head_size':500,\n",
    "    'num_heads':10,\n",
    "    'ff_dim': 500,\n",
    "    'dropout':0.59,\n",
    "    'learning_rate': 0.00005,\n",
    "    'epochs': 800,\n",
    "    'batch_size': 30,\n",
    "}\n",
    "'''\n",
    "\n",
    "# Bayesian optimization\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=INTENTOS, trials=trials)\n",
    "\n",
    "#Obtener el valor de la función objetivo del mejor ensayo\n",
    "best_trial = trials.best_trial\n",
    "hist = best_trial['result']['hist']\n",
    "best_model = best_trial['result']['model']\n",
    "\n",
    "# Obtener una lista de los resultados de todas las evaluaciones\n",
    "all_results = [trial['result'] for trial in trials]\n",
    "\n",
    "# Mejores hiperparámetros encontrados\n",
    "best_params = space_eval(space, best)\n",
    "best_params\n",
    "\n",
    "\"\"\"# 3.Evaluacion del modelo\"\"\"\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(hist.history['loss'], color = 'orange')\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Optimized Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "#Se realiza prediccion\n",
    "results = best_model.predict(X_test)\n",
    "\n",
    "results = results.reshape(shape_y_test)\n",
    "y_grafico = Y_test.reshape(shape_y_test)\n",
    "\n",
    "#Grafico de prediccion con el valor real\n",
    "tiempo=[x for x in range(y_grafico.shape[0])]\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.plot(tiempo,results)\n",
    "plt.ylabel('Global_active_power', size=15)\n",
    "plt.plot(tiempo,y_grafico)\n",
    "plt.xlabel('Time step', size=15)\n",
    "plt.legend(['Prediccion','Real'])\n",
    "plt.show()\n",
    "\n",
    "#Metricas de precision del modelo\n",
    "score = best_model.evaluate(X_test, Y_test, verbose = 0)\n",
    "print('MSE:', score[1])\n",
    "print('RMSE:', score[2])\n",
    "print('MAE:', score[3])\n",
    "print('MAPE:', score[4])\n",
    "\n",
    "fin = time.time()\n",
    "print(f\"El código se ejecutó en {(fin - inicio)/60} minutos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "# Graficar los resultados\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.figure(figsize=(10,6))\n",
    "train_original_range = range(len(Y_train_aux))\n",
    "test_range = range(len(Y_train_aux), len(Y_train_aux) + len(y_grafico))\n",
    "plt.plot(train_original_range, Y_train_aux, label='train')\n",
    "plt.plot(test_range, y_grafico, label='Test')\n",
    "plt.plot(test_range, results, label='Transformer Test Prediction')\n",
    "plt.title('Optimized Support Vector Machine Prediction')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('tiempo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'dropout': 0.42431109331839173,\n",
       " 'epochs': 5,\n",
       " 'ff_dim': 256,\n",
       " 'head_size': 64,\n",
       " 'learning_rate': 4.283656011946714e-05,\n",
       " 'num_heads': 6}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
